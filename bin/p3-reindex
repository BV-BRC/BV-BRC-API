#!/usr/bin/env node

const Config = require('../config')
const opts = require('commander')
const { httpStreamRequest } = require('../util/http')

const Fs = require('fs-extra')
const Path = require('path')
const QUEUE_DIRECTORY = Config.get('queueDirectory')

const Url = require('url')
const SOLR_URL = Config.get('solr').url
const parsedSolrUrl = Url.parse(SOLR_URL)

if (require.main === module) {
  opts.option('-k, --key [value]', 'Index Key')
    .option('-c, --cores [values]', 'Cores')
    .parse(process.argv)

  if (!opts.key) {
    console.error('Must supply key')
    opts.help()
  }

  if (!opts.cores || opts.cores.length === 0) {
    console.error('Must supply cores')
    opts.help()
  }
  const cores = opts.cores.includes(',') ? opts.cores.split(',') : [ opts.cores ]

  reIndexGenome(opts.key, cores)
}

function reIndexGenome (key, cores) {
  console.log(`${key}, ${cores}, ${Array.isArray(cores)}`)

  Fs.readJson(Path.join(QUEUE_DIRECTORY, 'history', key), { encoding: 'utf8' }, (err, data) => {
    if (err) {
      console.error(`${err}`)
      return
    }

    cores.forEach((core) => {
      const path = data.files[core].path

      postDocs(path, core).then((body) => {
        const resp = JSON.parse(body)
        if (resp.responseHeader.status === 0) {
          console.log(`${core} is indexed`)
        } else {
          console.error(resp)
        }
      }, (err) => {
        console.error(`${err}`)
      })
    })
  })
}

function postDocs (filePath, type) {
  const readStream = Fs.createReadStream(filePath)
  return httpStreamRequest({
    hostname: parsedSolrUrl.hostname,
    port: parsedSolrUrl.port,
    method: 'POST',
    headers: {
      'Content-Type': 'application/json'
    },
    path: `/solr/${type}/update?wt=json&overwrite=true&commit=false`
  }, readStream)
}
